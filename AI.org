* Artificial Intelligence
** Kind
*** AI
**** エキスパートシステム
**** CBR 事例ベース推論
**** ベイジアン・ネットワーク
*** CI
**** ニューラルネットワーク
**** ファジィ制御
**** 進化的計算
** Field
*** Neural Network ニューラルネットワーク
**** About
- 
  ニューロンをコンピュータ素子によるノードで表し、ノード間を信号線でつなぐことで作られる。

***** 学習と想起
****** 学習
- 
  パーセプトロンは、「学習」と「想起」という演算を繰り返すことで動作する。
  学習は、ノード間の重みや活性化関数の形状を変化させること。
  教師信号がある場合は期待する出力が得られるように重みや活性化関数を変更する。
  教師信号がない場合、ノード間の発火状態が系全体の安定化に沿うように、重みなどを変更する。
  
  - 教師なし学習
    - 誤差訂正学習
      教師信号を入力したときの期待出力と実際の出力が同じになるように変更する。
  - 教師あり学習
    - ヘッブ型学習
      隣接ニューロンが共に発火すればその結合重みを増すように変更する

****** 想起
- 
  任意のデータを入力すると、ネットワークが動き出して何らかの出力が得られる。この過程を想起という。

- 
  階層型の想起は、1回の想起演算で成功・失敗が決まる。
  入力が教師信号と異なっても、出力が教師信号と一致する場合を"連想"という。

- 
  相互結合型の想起は、系全体が安定状態になるまで想起演算を繰り返す。
  系の安定状態とは、想起演算を繰り返しても各ノードの値が変化しなくなる状態。
  それが記憶内容に一致すれば想起成功、そうでなければ想起失敗。

***** 構造
****** 階層構造型
- ノードを階層的に並べ、各階層間のノードは完全結合とするが、階層内はつながない
  信号の流れに方向性ができ、脳のニューロン信号に近いが、適用に限界があり相互結合型構造が生まれた。
  この考え方に基づき最初に考えられたのがパーセプトロン。

****** 相互結合型
- すべてのノードを対等に繋ぐ。完全結合では線が多くなりすぎるため、選択的に繋ぐこともある。
  方向性がなく、各ノードの値とノード間の重みを、計全体として安定化する方向に変化させていく、という考え方。
  ホップフィールドネットワークなどがある。

**** MacCulloch, Pitts マカロック・ピッツのモデル
- 
  一つのニューロンにシナプスを通じて多数のニューロンからの入力信号が入り、
  それらの信号の和が一定の強さを超えれば、そのニューロンは発火し、軸索を通じて他のニューロンに信号を出力する。
- 
  出力 = f(Σ W_i X_i)
  W_i:ニューロン間の結合の強さ、X_i:書くニューロンからの入力
  fは活性化関数。総和から発火するかどうか決める。

  - 活性化関数
    - 閾値モデル
      f : if Σxw >= a -> 1, else 0
    - シグモイド
      f : 1 / ( 1 + e^(α(a - Σwx)))

**** Perceptron パーセプトロン
- 
  Frank Rosenblattが考案したもっとも初歩的な階層型ネットワーク。
  モデルはロジスティック回帰と等価。
***** 構造
- 
  受容器(Sensory Unit)、連合器(Association Unit)、応答器(Response Unit)というノード階層からなる3層構造。
  受容器と連合器は重み固定の完全結合、連合器とおうとうきは重み可変の完全結合。
  信号は受信機から連合器、応答器の方向に流れる一方通行。
  受容器の各ノードに値を設定することがネットワークへの入力となり、出力は応答器の各ノードの値として得られる。
  
***** 学習
- 
  教師信号入力に対し、期待信号が出力されるように連合器と応答器の間の重みを変化させること。
  期待出力が1なのに0が出力された時は重みを増し、逆の時は重みを減らす。
  
- 学習収束定理
  教師信号が線形分離であれば、学習は必ず収束する。
  （逆に線形分離可能でない場合、学習が収束しない可能性が高い）

- 誤差訂正学習
  W <= W + ηX(P-Y)
  教師信号の出力をPとし、両者の差をフィードバックして、誤差が0となるようにする。

- 線形分離可能性
  
**** Hopfield Network ホップフィールドネットワーク
- 
  
**** 活性化関数
***** ステップ関数
- Def
  h(x) = 1 (x > 0)
  h(x) = 0 (x <= 0)
***** sigmoid function シグモイド関数
- Def
  h(x) = 1 / 1 + exp(-x)
***** ReLU関数
- Rectified Linear Unit
- Def
  h(x) = x (x > 0)
  h(x) = 0 (x <= 0)
*** ファジィ
*** 遺伝的アルゴリズム
*** 探索
*** ゲーム戦略
*** 機械学習
- [[file:MachineLearning.org][MachineLearning]]
*** Deep Learning 深層学習
*** 知識表現
*** エキスパートシステム
*** 音声認識
*** 感性処理
*** 自然言語処理
*** 情報検索
*** 推論
*** データマイニング
*** ヒューマンインターフェース
*** プランニング
*** マルチエージェント
*** ロボット
** Study Theme
*** 脳科学
*** ニューラルネットワーク
*** ファジィ
*** 機械学習
*** 深層学習
*** 論理推論
*** Data Mining
*** ベイジアンネットワーク
*** 知識表現
*** 遺伝的アルゴリズム
*** Web
*** 検索エンジン
*** エージェント
*** ソフトコンピューティング
*** 自然言語
*** オントロジー
*** シソーラス
*** コーパス
*** 画像処理
*** 音声
*** パターン認識
*** HCI/HAI
*** クラウド
*** Linked Data
*** 教育支援
*** 農業
*** マーケティング
*** 財務
*** 観光
*** 囲碁将棋
*** ロボット
*** Mobile
*** ウェアラブル
*** ユビキタス
*** 並列
*** 医療
*** 複雑系
*** Virtual Reality
*** バイオ
*** 法律
*** SNS
*** Singularity
** History
*** 1956
- 
  ダートマスでの会議で、John MacCarthy, Marvin Minskyらが共同で提案したのが始まりと言われる。

** Glossary
*** 強いAI, 弱いAI
- 強いAI
  本当に知能のある機械
- 弱いAI
  知能があるように見える機械
*** Singularity 技術的特異点
*** フレーム問題

** Memo
